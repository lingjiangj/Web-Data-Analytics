{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Assignment 2 Part A - Getting the data on 10 K filings in a dataframe (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### In this part of the assignment you are provided a list of mutual funds and the companies that were dropped from their portfolios.  We want to obtain the 10-K filings for these companies.  In the file (Dropped_Companies.csv), there is a column called \"Name of Stock\".  Load the file, extract a list of all the companies in that column, then find the 10-K links for all these companies.  Feel free to utilize Beautiful Soup and Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### First, start with the importing of the relevant libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### You will be populating the following lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weblink = []\n",
    "filing_type = []\n",
    "company_name = []\n",
    "date = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Upload the Dropped_Companies.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dropped_Companies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### The information on 10-K, 10-K/A, 10-K 405 of a company is in the the following link:\n",
    "\n",
    "##### 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&company=' + Company+Name (a space between the two companies is replaced by a '+') + '&type=10-K&dateb=&owner=exclude&count=100'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### So, your task will be to collect information on Company Name, Date of Filing, Filing Type and Link to the 'Document' of the filing type for each of the companies in the final dropped list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Hint: Make sure to collect all the filing links in every companies page. Number of filings available for each company varies, so make sure you take care of that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generat a list of company links to the information on 10-k... \n",
    "company_link = []\n",
    "for name in df[\"Name of Stock\"]:\n",
    "    name_list = name.split(\" \")\n",
    "    name = ('+').join(name_list)\n",
    "    link = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&company='+name+ '&type=10-K&dateb=&owner=exclude&count=100'\n",
    "    company_link.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using BeautifulSoup to get Filling Data/Filling Weblink/Filling Date\n",
    "import bs4 as bs\n",
    "from bs4 import SoupStrainer\n",
    "import codecs\n",
    "import time\n",
    "\n",
    "for link_number in range(0,len(company_link)):\n",
    "    html = urllib.request.urlopen(company_link[link_number])\n",
    "    html = html.read().decode('utf-8')\n",
    "    \n",
    "    soup = bs.BeautifulSoup(html)\n",
    "    \n",
    "    infotable = soup.find_all(\"table\", summary = \"Results\")\n",
    "    if infotable[0].find_all(\"tr\")[0].find_all(\"th\")[0].getText() == \"Filings\":\n",
    "        for row in infotable[0].find_all(\"tr\")[1:]:\n",
    "            columns = row.find_all(\"td\")\n",
    "            date.append(columns[3].getText())\n",
    "            filing_link = columns[1].find(\"a\").get(\"href\")\n",
    "            weblink.append('https://www.sec.gov'+filing_link)\n",
    "            type = filing_link[columns[1].find(\"a\").get(\"href\").find(\".\")+1:]\n",
    "            filing_type.append(columns[0].getText())\n",
    "            company_name.append(df[\"Name of Stock\"][link_number])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### After populating the lists, you need to save the data in the following csv file, using what you have learned from the pandas lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "outputdf = pd.DataFrame({\"Company Name\":company_name,\"Date of Filing\":date, \"Filing Type\":filing_type,\"Link\":weblink})\n",
    "outputdf.to_csv('10K Links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
